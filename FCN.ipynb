{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOROQVN6P/3IeIe8gwoHUVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloelitrico/Deep-RNN/blob/master/FCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8-rYN1Ivxuv",
        "colab_type": "text"
      },
      "source": [
        "## **Deep Recurrent Neural Networks for Magnetic Resonance Fingerprinting**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEud-g640ftC",
        "colab_type": "text"
      },
      "source": [
        "Mount drive to google drive for file import and export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRZPWPeZP4nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs7iwS2x0t_9",
        "colab_type": "text"
      },
      "source": [
        "Importing package dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUB6itWDJDpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0P5pqXx0q0L",
        "colab_type": "text"
      },
      "source": [
        "# Data pre-processing \n",
        "Before training a model, the data is normalized, corrupt with noise, and in certain situations, re-shaped to enhance training accuracy and speed. \n",
        "Both MRF signals and brain phantoms are pre-processed before being feed into the algorithms. \n",
        "Below are the functions used during the data pre-processing step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZXoxPiPvAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(X1, X2, y):\n",
        "  \"\"\"\n",
        "  Normalize and re-scale MRF signal data\n",
        "\n",
        "  Input: X and y values of imported data\n",
        "  Output: normalized X values and scaled y values \n",
        "  \"\"\"\n",
        "  # Normalize input data\n",
        "  X1 = normalize(X1)\n",
        "  X2 = normalize(X2)\n",
        "\n",
        "  #Scale Off resonance freqeuncy \n",
        "  y[:,2] = y[:, 2] *1000\n",
        "\n",
        "  return X1, X2, y\n",
        "\n",
        "\n",
        "def noise(signal):\n",
        "  \"\"\"\n",
        "  Corrupt signal with 1% white Gaussian noise\n",
        "\n",
        "  Input: signal in the form of an array of integers\n",
        "  Output: signal with added 1% gaussian noise\n",
        "  \"\"\"\n",
        "  stdv = np.std(signal)\n",
        "  mu, sigma = 0, 0.01 # mean:0 and stdv:1%\n",
        "  noise = np.random.normal(mu, sigma*stdv, np.shape(signal)) \n",
        "  \n",
        "  return signal + noise\n",
        "\n",
        "\n",
        "def brain_preprocess(phantom_re, phantom_im, phantom_rf):\n",
        "  \"\"\"\n",
        "  Normalize and re-scale brain phantom data\n",
        "\n",
        "  Input: Real and imaginary MRF signal values of brain phantom data\n",
        "  Output: normalized real and imaginary MRF signals and scaled off-resonance frequency values \n",
        "  \"\"\"\n",
        "  # Normalizing input data\n",
        "  for i in range(len(phantom_re)):\n",
        "    phantom_re[i] = normalize(phantom_re[i])\n",
        "  for i in range(len(phantom_im)):\n",
        "    phantom_im[i] = normalize(phantom_im[i])\n",
        "  \n",
        "  return phantom_re, phantom_im, phantom_rf*1000 #rescaling data\n",
        "\n",
        "\n",
        "def brain_noise(phantom):\n",
        "  \"\"\"\n",
        "  Corrupt brain phantom (MRF signals) with 1% white Gaussian noise\n",
        "\n",
        "  Input: brain phantom in the form of an array of MRF signals\n",
        "  Output: brain phantom MRF signals with added 1% gaussian noise\n",
        "  \"\"\"\n",
        "  for i in range(len(phantom)):\n",
        "    for j in range(len(phantom[i])):\n",
        "      phantom[i][j] = noise(phantom[i][j])\n",
        "  return phantom\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB3py3QA3fhp",
        "colab_type": "text"
      },
      "source": [
        "# Custom Metrics\n",
        "\n",
        "Loss and accuracy metrics offered by Tensorflow are not specific to the seperate T1, T2, and B0 values. Thus, metrics need to be customized to analyze the true accuracy of each individual parameter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP7LXlXH0_yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def t1_MAPE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T1 mean absolute percentage error\n",
        "\n",
        "  Input: true and predicted values\n",
        "  Output: T1 MAPE\n",
        "  \"\"\"\n",
        "  difference = tf.math.divide(tf.math.abs(tf.math.subtract(y_true[:,0], y_pred[:,0])), y_true[:,0])\n",
        "  t1_MAPE = tf.math.reduce_mean(difference)\n",
        "  return t1_MAPE *100\n",
        "\n",
        "\n",
        "def t2_MAPE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T2 mean absolute percentage error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T2 MAPE\n",
        "  \"\"\"\n",
        "  difference = tf.math.divide(tf.math.abs(tf.math.subtract(y_true[:,1], y_pred[:,1])), y_true[:,1])\n",
        "  t2_MAPE = tf.math.reduce_mean(difference)\n",
        "  return t2_MAPE *100\n",
        "\n",
        "\n",
        "def rf_MAPE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  B0 mean absolute percentage error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: B0 MAPE\n",
        "  \"\"\"\n",
        "  # Account for divide-by-zero\n",
        "  difference = tf.math.divide_no_nan(tf.math.abs(tf.math.subtract(y_true[:,2], y_pred[:,2])), tf.math.abs(y_true[:,2]))\n",
        "  rf_MAPE = tf.math.reduce_mean(difference)\n",
        "  return rf_MAPE *100\n",
        "\n",
        "\n",
        "def t1_MAE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T1 mean absolute error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T1 MAE\n",
        "  \"\"\"\n",
        "  difference = tf.math.abs(tf.math.subtract(y_true[:,0], y_pred[:,0]))\n",
        "  t1_MAE = tf.math.reduce_mean(difference)\n",
        "  return t1_MAE\n",
        "\n",
        "\n",
        "def t2_MAE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T2 mean absolute error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T2 MAE\n",
        "  \"\"\"\n",
        "  difference = tf.math.abs(tf.math.subtract(y_true[:,1], y_pred[:,1]))\n",
        "  t2_MAE = tf.math.reduce_mean(difference)\n",
        "  return t2_MAE\n",
        "\n",
        "\n",
        "def rf_MAE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  B0 mean absolute error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: B0 MAE\n",
        "  \"\"\"\n",
        "  difference = tf.math.abs(tf.math.subtract(y_true[:,2], y_pred[:,2]))\n",
        "  rf_MAE = tf.math.reduce_mean(difference)\n",
        "  return rf_MAE\n",
        "\n",
        "\n",
        "def t1_RMSE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T1 root mean squared error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T1 RMSE\n",
        "  \"\"\"\n",
        "  difference = tf.math.squared_difference(y_true[:,0], y_pred[:,0])\n",
        "  t1_MAE = tf.math.sqrt(tf.math.reduce_mean(difference))\n",
        "  return t1_MAE\n",
        "\n",
        "\n",
        "def t2_RMSE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T2 root mean squared error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T2 RMSE\n",
        "  \"\"\"\n",
        "  difference = tf.math.squared_difference(y_true[:,1], y_pred[:,1])\n",
        "  t2_MAE = tf.math.sqrt(tf.math.reduce_mean(difference))\n",
        "  return t2_MAE\n",
        "\n",
        "\n",
        "def rf_RMSE(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  B0 root mean squared error\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: B0 RMSE\n",
        "  \"\"\"\n",
        "  difference = tf.math.squared_difference(y_true[:,2], y_pred[:,2])\n",
        "  rf_MAE = tf.math.sqrt(tf.math.reduce_mean(difference))\n",
        "  return rf_MAE\n",
        "\n",
        "\n",
        "def t1_accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T1 prediction accuracy\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T1 accuracy\n",
        "  \"\"\"\n",
        "  t1_accuracy = 1-tf.math.reduce_mean(tf.math.abs(y_true[:,0]-y_pred[:,0])/(tf.math.abs(y_true[:,0])),axis=0)\n",
        "  return t1_accuracy\n",
        "\n",
        "\n",
        "def t2_accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T2 prediction accuracy\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T2 accuracy\n",
        "  \"\"\"\n",
        "  t2_accuracy = 1-tf.math.reduce_mean(tf.math.abs(y_true[:,1]-y_pred[:,1])/(tf.math.abs(y_true[:,1])),axis=0)\n",
        "  return t2_accuracy\n",
        "\n",
        "\n",
        "def rf_accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  B0 prediction accuracy\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: B0 accuracy\n",
        "  \"\"\"\n",
        "  # Account for divid-by-zero error\n",
        "  rf_accuracy = 1-tf.math.reduce_mean(tf.math.divide_no_nan(tf.math.abs(y_true[:,2]-y_pred[:,2]),(tf.math.abs(y_true[:,2]))),axis=0)\n",
        "  return rf_accuracy\n",
        "\n",
        "\n",
        "def t1_MAEstdv(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T1 Mean absolute error standard deviation\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T1 MAE stdv\n",
        "  \"\"\"\n",
        "  t1_MAEstdv = tf.math.sqrt(tf.math.reduce_mean(tf.math.squared_difference((tf.math.abs(y_true[:,0]-y_pred[:,0])), t1_MAE(y_true, y_pred))))\n",
        "  return t1_MAEstdv\n",
        "\n",
        "\n",
        "def t2_MAEstdv(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  T2 Mean absolute error standard deviation\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: T2 MAE stdv\n",
        "  \"\"\"\n",
        "  t2_MAEstdv = tf.math.sqrt(tf.math.reduce_mean(tf.math.squared_difference((tf.math.abs(y_true[:,1]-y_pred[:,1])), t2_MAE(y_true, y_pred))))\n",
        "  return t2_MAEstdv\n",
        "\n",
        "\n",
        "def rf_MAEstdv(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  B0 Mean absolute error standard deviation\n",
        "  \n",
        "  Input: true and predicted values\n",
        "  Output: B0 MAE stdv\n",
        "  \"\"\"\n",
        "  rf_MAEstdv = tf.math.sqrt(tf.math.reduce_mean(tf.math.squared_difference((tf.math.abs(y_true[:,2]-y_pred[:,2])), rf_MAE(y_true, y_pred))))\n",
        "  return rf_MAEstdv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMkYZp0V5D9q",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network Models\n",
        "The neural network architectures for the DRONE, simple RNNs, and deep RNNs are defined below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDcPeZt31Vkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DRONE_1(features = 2):\n",
        "  \"\"\"\n",
        "  Fully connected neural network accepting imaginary signal values as input and outputs predicted t1 and t2 values\n",
        "  Neural network: 1 dimensional input layer, Dense 300 (activation tanh), Dense 300 (activation tanh), 2 dimensional output layer (activation relu)\n",
        "  \"\"\"\n",
        "\n",
        "  model = Sequential() \n",
        "  model.add(Dense(300, activation='tanh')) #first hidden layer with 300 nodes\n",
        "  model.add(Dense(300, activation='tanh')) #second hidden layer\n",
        "  model.add(Dense(features, activation='relu')) #output layer \n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, t1_MAE, t2_MAE, t1_accuracy, t2_accuracy, t1_RMSE, t2_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def DRONE_2(features = 3):\n",
        "  \"\"\"\n",
        "  Fully connected neural network accepting real and imaginary parts of the signal as input and outputs predicted t1, t2, off res values\n",
        "  Neural network: 2 stream input layer, Dense 300 (activation tanh), Dense 300 (activation tanh), 3 dimensional output layer (activation linear)\n",
        "  \"\"\"\n",
        "\n",
        "  input1 = keras.layers.Input(shape=(1000, ))\n",
        "  input2 = keras.layers.Input(shape=(1000,))\n",
        "  merged = keras.layers.Concatenate(axis=1)([input1, input2])\n",
        "  dense1 = keras.layers.Dense(300, input_dim=2, activation=keras.activations.tanh)(merged)\n",
        "  dense2 = keras.layers.Dense(300, activation=keras.activations.tanh)(dense1)\n",
        "  output = keras.layers.Dense(features, activation='linear', use_bias=True)(dense2)\n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  model = keras.models.Model([input1, input2], output)\n",
        "  model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, rf_MAPE, t1_MAE, t2_MAE, rf_MAE, t1_accuracy, t2_accuracy, rf_accuracy, t1_RMSE, t2_RMSE, rf_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def LSTM_1(features = 2):\n",
        "  \"\"\"\n",
        "  Long Short Term Memory neural network (LSTM RNN) accepting imaginary parts of the signal as input and outputs predicted t1, t2 values\n",
        "  Neural network: 1 dimensional input layer, Reshape (10,100), LSTM 100, 2 dimensional output layer (activation relu)\n",
        "  \"\"\"\n",
        "\n",
        "  model = Sequential() \n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Reshape((10, 100)))\n",
        "  model.add(layers.LSTM(100)) \n",
        "  model.add(layers.Dense(features, activation='relu')) \n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, t1_MAE, t2_MAE, t1_accuracy, t2_accuracy, t1_RMSE, t2_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def deep_LSTM_1(features = 2):\n",
        "  \"\"\"\n",
        "  Deep Long Short Term Memory neural network (LSTM RNN) accepting imaginary parts of the signal as input and outputs predicted t1, t2 values\n",
        "  Neural network: 1 dimensional input layer, Reshape (10,100), LSTM 100, LSTM 50, 2 dimensional output layer (activation relu)\n",
        "  \"\"\"\n",
        "  model = Sequential() \n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Reshape((10, 100)))\n",
        "  model.add(layers.LSTM(100, return_sequences=True))\n",
        "  model.add(layers.LSTM(50)) \n",
        "  model.add(layers.Dense(features, activation='relu')) \n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, t1_MAE, t2_MAE, t1_accuracy, t2_accuracy, t1_RMSE, t2_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def LSTM_2(features = 3):\n",
        "  \"\"\"\n",
        "  Long Short Term Memory neural network (LSTM RNN) accepting real and imaginary parts of the signal as input and outputs predicted t1, t2, and off res values\n",
        "  Neural network: 2 input streams input layer, Reshape (10,100) (for both inputs), LSTM 100, 3 dimensional output layer (activation linear)\n",
        "  \"\"\"\n",
        "  input1 = keras.layers.Input(shape=(1000, ))\n",
        "  input2 = keras.layers.Input(shape=(1000, ))\n",
        "  reshape1 = keras.layers.Reshape((10, 100))(input1)\n",
        "  reshape2 = keras.layers.Reshape((10, 100))(input2)\n",
        "  merged = keras.layers.Concatenate(axis=1)([reshape1, reshape2])\n",
        "  lstm = keras.layers.LSTM(100)(merged)\n",
        "  output = keras.layers.Dense(features, activation=keras.activations.linear, use_bias=True)(lstm)\n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "\n",
        "  model = keras.models.Model([input1, input2], output)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, rf_MAPE, t1_MAE, t2_MAE, rf_MAE, t1_accuracy, t2_accuracy, rf_accuracy, t1_RMSE, t2_RMSE, rf_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def deep_LSTM_2(features = 3):\n",
        "  \"\"\"\n",
        "  Deep Long Short Term Memory neural network (LSTM RNN) accepting real and imaginary parts of the signal as input and outputs predicted t1, t2, and off res values\n",
        "  Neural network: 2 input streams, Reshape (10,100) (for both inputs), LSTM 100, LSTM 50, 3 dimensional output layer (activation linear)\n",
        "  \"\"\"\n",
        "  input1 = keras.layers.Input(shape=(1000, ))\n",
        "  input2 = keras.layers.Input(shape=(1000, ))\n",
        "  reshape1 = keras.layers.Reshape((10, 100))(input1)\n",
        "  reshape2 = keras.layers.Reshape((10, 100))(input2)\n",
        "  merged = keras.layers.Concatenate(axis=1)([reshape1, reshape2])\n",
        "  lstm1 = keras.layers.LSTM(100, return_sequences=True)(merged)\n",
        "  lstm2 = keras.layers.LSTM(50)(lstm1)\n",
        "  output = keras.layers.Dense(features, activation=keras.activations.linear, use_bias=True)(lstm2)\n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "\n",
        "  model = keras.models.Model([input1, input2], output)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, rf_MAPE, t1_MAE, t2_MAE, rf_MAE, t1_accuracy, t2_accuracy, rf_accuracy, t1_RMSE, t2_RMSE, rf_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def GRU_1(features = 2):\n",
        "  \"\"\"\n",
        "  GRU neural network accepting the imaginary part of the signal as input and outputs predicted t1 and t2 values\n",
        "  Neural network: 1 dimensional input layer, GRU 100, 2 dimensional output layer (activation relu)\n",
        "  \"\"\"\n",
        "  model = Sequential() \n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Reshape((10, 100)))\n",
        "  model.add(layers.GRU(100)) \n",
        "  model.add(layers.Dense(features, activation='relu')) \n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, t1_MAE, t2_MAE, t1_accuracy, t2_accuracy, t1_RMSE, t2_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def deep_GRU_1(features = 2):\n",
        "  \"\"\"\n",
        "  Deep GRU neural network accepting the imaginary part of the signal as input and outputs predicted t1 and t2 values\n",
        "  Neural network: 1 dimensional input layer, GRU 100, GRU 50, 2 dimensional output layer (activation relu)\n",
        "  \"\"\"\n",
        "  model = Sequential() \n",
        "  \n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.layers.Reshape((10, 100)))\n",
        "  model.add(layers.GRU(100, return_sequences=True)) \n",
        "  model.add(layers.GRU(50)) \n",
        "  model.add(layers.Dense(features, activation='relu')) \n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, t1_MAE, t2_MAE, t1_accuracy, t2_accuracy, t1_RMSE, t2_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def GRU_2(features = 3):\n",
        "  \"\"\"\n",
        "  GRU neural network accepting real and imaginary parts of the signal as input and outputs predicted t1, t2, off res values\n",
        "  Neural network: 2 stream input layer, Reshape (10,100) (for both inputs), GRU 100, 3 dimensional output layer (activation linear)\n",
        "  \"\"\"\n",
        "  input1 = keras.layers.Input(shape=(1000, ))\n",
        "  input2 = keras.layers.Input(shape=(1000,))\n",
        "  reshape1 = keras.layers.Reshape((10, 100))(input1)\n",
        "  reshape2 = keras.layers.Reshape((10, 100))(input2)\n",
        "  merged = keras.layers.Concatenate(axis=1)([reshape1, reshape2])\n",
        "  gru = keras.layers.GRU(100)(merged)\n",
        "  output = keras.layers.Dense(features, activation=keras.activations.linear, use_bias=True)(gru)\n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "\n",
        "  model = keras.models.Model([input1, input2], output)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, rf_MAPE, t1_MAE, t2_MAE, rf_MAE, t1_accuracy, t2_accuracy, rf_accuracy, t1_RMSE, t2_RMSE, rf_RMSE])\n",
        "\n",
        "  return model\n",
        "\n",
        "def deep_GRU_2(features = 3):\n",
        "  \"\"\"\n",
        "  Deep GRU neural network accepting real and imaginary parts of the signal as input and outputs predicted t1, t2, off res values\n",
        "  Neural network: 2 stream input layer, Reshape (10,100) (for both inputs), GRU 100, GRU 50, 3 dimensional output layer (activation linear)\n",
        "  \"\"\"\n",
        "  input1 = keras.layers.Input(shape=(1000, ))\n",
        "  input2 = keras.layers.Input(shape=(1000,))\n",
        "  reshape1 = keras.layers.Reshape((10, 100))(input1)\n",
        "  reshape2 = keras.layers.Reshape((10, 100))(input2)\n",
        "  merged = keras.layers.Concatenate(axis=1)([reshape1, reshape2])\n",
        "  gru1 = keras.layers.GRU(100, return_sequences=True)(merged)\n",
        "  gru2 = keras.layers.GRU(50)(gru1)\n",
        "  output = keras.layers.Dense(features, activation=keras.activations.linear, use_bias=True)(gru2)\n",
        "\n",
        "  keras.optimizers.Adam(learning_rate=0.001, clipnorm=0.5)\n",
        "\n",
        "  model = keras.models.Model([input1, input2], output)\n",
        "  model.compile(optimizer = 'adam', loss=\"mean_squared_error\", metrics=['accuracy', t1_MAPE, t2_MAPE, rf_MAPE, t1_MAE, t2_MAE, rf_MAE, t1_accuracy, t2_accuracy, rf_accuracy, t1_RMSE, t2_RMSE, rf_RMSE])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KMxDhg969-F",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization\n",
        "Plotting and visualizing prediction results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaoeCHOg1grI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metric(history, metric):\n",
        "  \"\"\"\n",
        "  Plot desired metric with its validation curve\n",
        "\n",
        "  Input: history and 1 desired metric\n",
        "  Output: graphed results\n",
        "  \"\"\"\n",
        "  train_metrics = history.history[metric]\n",
        "  val_metrics = history.history['val_'+metric]\n",
        "  epochs = range(1, len(train_metrics) + 1)\n",
        "  plt.plot(epochs, train_metrics, 'b--')\n",
        "  plt.plot(epochs, val_metrics, 'r-')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_accuracies(history, metrics):\n",
        "  \"\"\"\n",
        "  Plot all accuracies on the same plot\n",
        "  \n",
        "  Input: training history and list of accruacies\n",
        "  Output: graphed accuracies\n",
        "  \"\"\"\n",
        "  for metric in metrics:\n",
        "    plt.plot(training.history[metric])\n",
        "  \n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(metrics)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_true_v_predicted(y_true, y_predicted):\n",
        "  \"\"\"\n",
        "  Plotting true values against predicted values\n",
        "\n",
        "  Input: true values and predicted values\n",
        "  Output: plots of each parameter\n",
        "  \"\"\"\n",
        "  metrics = ['T1', 'T2', 'RF']\n",
        "  i = 0\n",
        "  while i < np.shape(y_true)[1] :\n",
        "    x = np.linspace(np.min(y_true[:,i]), np.max(y_true[:,i]))\n",
        "    plt.scatter(y_true[:,i], y_predicted[:,i])\n",
        "    plt.plot(x, x + 0, '-r')\n",
        "    plt.xlabel('Reference '+ metrics[i] +' (ms)')\n",
        "    plt.ylabel('Estimated '+ metrics[i] +' (ms)')\n",
        "    plt.show() \n",
        "    rmse = math.sqrt(mean_squared_error(y_true[:,i], y_predicted[:,i]))\n",
        "    score = r2_score(y_true[:,i], y_predicted[:,i])\n",
        "    print(\"RMSE:\", rmse)\n",
        "    print(\"R^2:\", score)\n",
        "    i+=1\n",
        "\n",
        "\n",
        "def show_prediction_metrics(y_test, y_predicted, parameters =2):\n",
        "  \"\"\"\n",
        "  Printing the prediction metrics from the testing data set\n",
        "  \"\"\"\n",
        "  print('t1_MAPE: ', np.array(t1_MAPE(y_test, y_predicted)))\n",
        "  print('t2_MAPE: ', np.array(t2_MAPE(y_test, y_predicted)))\n",
        "  print('t1_MAE: ', np.array(t1_MAE(y_test, y_predicted)))\n",
        "  print('t2_MAE: ', np.array(t2_MAE(y_test, y_predicted)))\n",
        "  print('t1_RMSE: ', np.array(t1_RMSE(y_test, y_predicted)))\n",
        "  print('t2_RMSE: ', np.array(t2_RMSE(y_test, y_predicted)))\n",
        "  print('t1_accuracy: ', np.array(t1_accuracy(y_test, y_predicted)))\n",
        "  print('t2_accuracy: ', np.array(t2_accuracy(y_test, y_predicted)))\n",
        "  print('t1_MAEstdv: ', np.array(t1_MAEstdv(y_test, y_predicted)))\n",
        "  print('t2_MAEstdv: ', np.array(t2_MAEstdv(y_test, y_predicted)))\n",
        "\n",
        "  if parameters == 3:\n",
        "    print('rf_MAPE: ', np.array(rf_MAPE(y_test, y_predicted)))\n",
        "    print('rf_MAE: ', np.array(rf_MAE(y_test, y_predicted)))\n",
        "    print('rf_RMSE: ', np.array(rf_RMSE(y_test, y_predicted)))\n",
        "    print('rf_accuracy: ', np.array(rf_accuracy(y_test, y_predicted)))\n",
        "    print('rf_MAEstdv: ', np.array(rf_MAEstdv(y_test, y_predicted)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjl842srEGfc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Brain Reconstruction\n",
        "Data processing and visualization of brain phantoms\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl8urlDnEGIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_brain_predictions(phantom_re, phantom_im, model, features):\n",
        "  \"\"\"\n",
        "  Reconstruct a brain image from a 3D array of MRF signals\n",
        "\n",
        "  Input: 3D array of real and imaginary parts of the MRF signals, predefined and trained neural network model of choice, number of features that are predicted (t1, t2, rf)\n",
        "  Output: 3D array of predicted values\n",
        "  \"\"\"\n",
        "  y_predicted = []\n",
        "  \n",
        "  for i in range(len(phantom_re)):\n",
        "    if (features == 2):\n",
        "      y_predicted.append(model.predict([phantom_im[i]]))\n",
        "    else:\n",
        "      y_predicted.append(model.predict([phantom_re[i], phantom_im[i]]))\n",
        "\n",
        "  return np.array(y_predicted)\n",
        "\n",
        "\n",
        "def mask_brain(y_predicted):\n",
        "  \"\"\"\n",
        "  Removes background from brain images\n",
        "\n",
        "  Input: brain image\n",
        "  Output: brain image with background set to 0\n",
        "  \"\"\"\n",
        "  for i in range(np.shape(y_predicted)[2]):\n",
        "    bg = y_predicted[0,0,i]\n",
        "    for row in range(np.shape(y_predicted)[0]):\n",
        "      for col in range(np.shape(y_predicted)[1]):\n",
        "        if y_predicted[row,col,i] == bg:\n",
        "          y_predicted[row,col,i] = 0\n",
        "  return y_predicted\n",
        "\n",
        "\n",
        "def show_brain(y_predicted, y_true):\n",
        "  \"\"\"\n",
        "  Plotting brain images on a heat map\n",
        "  \n",
        "  Input: predicted parameters 3D array, true parameters 3D array\n",
        "  Output: predicted brain image, true brain image, and the error (difference between the two images)\n",
        "  \"\"\"\n",
        "  # Visualize\n",
        "  for i in range(np.shape(y_predicted)[2]):\n",
        "    fig, axes = plt.subplots(ncols=3, figsize=(12, 12))\n",
        "    ax1, ax2, ax3 = axes\n",
        "    \n",
        "    im1 = ax1.imshow(y_predicted[:,:,i], cmap='hot', interpolation='nearest')\n",
        "    im2 = ax2.imshow(y_true[i,:,:], cmap='hot', interpolation='nearest')\n",
        "    im3 = ax3.imshow(tf.math.abs(y_true[i,:,:]-y_predicted[:,:,i]), cmap='hot', interpolation='nearest')\n",
        "  \n",
        "    ax1.axis('off')\n",
        "    ax2.axis('off')\n",
        "    ax3.axis('off')\n",
        "    plt.colorbar(im1, fraction=0.045, pad=0.05, ax=ax1)\n",
        "    plt.colorbar(im2, fraction=0.045, pad=0.05, ax=ax2)\n",
        "    plt.colorbar(im3, fraction=0.045, pad=0.05, ax=ax3)\n",
        "\n",
        "    fig.tight_layout()\n",
        "  \n",
        "\n",
        "def brain_accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculating predictive accuracy of brain reconstruction\n",
        "  \"\"\"\n",
        "  accuracy = []\n",
        "  for i in range(np.shape(y_true)[2]): \n",
        "    accuracy.append(1-tf.math.reduce_mean(tf.math.divide_no_nan(tf.math.abs(y_true[:,:,i]-y_pred[:,:,i]),(tf.math.abs(y_true[:,:,i])))))\n",
        "  return np.array(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw_slvA-EXiY",
        "colab_type": "text"
      },
      "source": [
        "# Importing Data\n",
        "Importing data, pre-processing, and defining model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaVa1jBiLrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import t1 t2 b0 dictionary and look up table\n",
        "with h5py.File('/content/drive/My Drive/Colab Notebooks/t1t2rfdict.mat', 'r') as file:\n",
        "    dict_im = np.array((file['dict_im']))\n",
        "    dict_re = np.array((file['dict_re']))\n",
        "    lut = np.array((file['lut'])) \n",
        "\n",
        "# Import brain phantom\n",
        "with h5py.File('/content/drive/My Drive/Colab Notebooks/brain_phantom.mat', 'r') as file:\n",
        "    phantom_re = (np.array((file['phantom_re']))).transpose(1, 2, 0)\n",
        "    phantom_im = (np.array((file['phantom_im']))).transpose(1, 2, 0)\n",
        "    phantom_t1 = np.array((file['T1_phantom']))\n",
        "    phantom_t2 = np.array((file['T2_phantom']))\n",
        "    phantom_rf = np.array((file['df_phantom']))\n",
        "\n",
        "\n",
        "# Data preprocessing \n",
        "dict_re, dict_im, lut = preprocess(dict_re, dict_im, lut)\n",
        "phantom_re, phantom_im, phantom_rf= brain_preprocess(phantom_re, phantom_im, phantom_rf)\n",
        "\n",
        "# Define model parameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkB0NQx1FRLi",
        "colab_type": "text"
      },
      "source": [
        "# Defining, Training, and Saving 2 parameter models\n",
        "Defining and training the models which predict 2 parameters: T1 and T2. These models include: DRONE_1, GRU_1, deep_GRU_1, LSTM_1, and deep_LSTM_1. \n",
        "\n",
        "T1 and T2 values are only encoded by the imaginary part of the MRF signal. Hence, only the imaginary component of the MRF signal is used to train these models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_krWzIcQizQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# T1 & T2\n",
        "X_train,X_test,y_train,y_test = train_test_split(dict_im,lut[:,:-1],test_size=0.2)\n",
        "\n",
        "# Create a basic model instance\n",
        "model = DRONE_1(np.shape(y_train)[1]) # or GRU_1, deep_GRU_1, LSTM_1, deep_LSTM_1\n",
        "\n",
        "# Training\n",
        "training = model.fit(noise(X_train), y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split = 0.2)\n",
        "\n",
        "#Save model and training history\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_1.h5') \n",
        "\n",
        "#Convert the training history to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(training.history) \n",
        "\n",
        "#Save to csv: \n",
        "hist_csv_file = '/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_1_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "#Plot training metrics\n",
        "plot_metric(training, 't1_accuracy')\n",
        "plot_metric(training, 't2_accuracy')\n",
        "plot_accuracies(training, ['t1_accuracy', 't2_accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZwOHKKWGaZ6",
        "colab_type": "text"
      },
      "source": [
        "# Testing 2 parameter models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbEtDEI7f7s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_1.h5', custom_objects={'t1_MAPE':t1_MAPE, 't2_MAPE':t2_MAPE, 't1_MAE':t1_MAE, 't2_MAE':t2_MAE, 't1_accuracy':t1_accuracy, 't2_accuracy':t2_accuracy, 't1_RMSE':t1_RMSE, 't2_RMSE':t2_RMSE})\n",
        "y_predicted = model.predict(X_test, verbose=1) \n",
        "plot_true_v_predicted(y_test, y_predicted)\n",
        "show_prediction_metrics(y_test, y_predicted)\n",
        "\n",
        "y_predicted = make_brain_predictions(brain_noise(phantom_re), brain_noise(phantom_im), model, 2)\n",
        "y_predicted = mask_brain(y_predicted)\n",
        "show_brain(y_predicted, np.array([phantom_t1, phantom_t2]))\n",
        "print(brain_accuracy(np.array([phantom_t1, phantom_t2]).transpose(1, 2, 0), y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD3FT1qmGm81",
        "colab_type": "text"
      },
      "source": [
        "# Defining, Training, and Saving 3 parameter models\n",
        "Defining and training the models which predict 2 parameters: T1, T2, and RF. These models include: DRONE_2, GRU_2, deep_GRU_2, LSTM_2, and deep_LSTM_2. \n",
        "\n",
        "T1, T2, and B0 values are encoded by the real and imaginary parts of the MRF signal. Hence, both component of the MRF signal are used to train these models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PjZ8CBODHDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ANN T1, T2, and RF\n",
        "X1_train,X1_test,X2_train,X2_test,y_train,y_test = train_test_split(dict_re,dict_im,lut,test_size=0.2)\n",
        "\n",
        "# Create a basic model instance\n",
        "model = DRONE_2(np.shape(y_train)[1]) # or GRU_2, deep_GRU_2, LSTM_2, deep_LSTM_2\n",
        "\n",
        "#Training\n",
        "training = model.fit([noise(X1_train), noise(X2_train)], y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2)\n",
        "\n",
        "#Save model and training history\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_2.h5') \n",
        "\n",
        "#Convert the training history to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(training.history) \n",
        "\n",
        "#Save to csv: \n",
        "hist_csv_file = '/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_2_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "#Plot training metrics\n",
        "plot_metric(training, 't1_accuracy')\n",
        "plot_metric(training, 't2_accuracy')\n",
        "plot_metric(training, 'rf_accuracy')\n",
        "plot_accuracies(training, ['t1_accuracy', 't2_accuracy', 'rf_accuracy']) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gtu9tY7G_jX",
        "colab_type": "text"
      },
      "source": [
        "# Testing 3 parameter models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSr5KngXrkHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/saved_model/model_DRONE_2.h5', custom_objects={'t1_MAPE':t1_MAPE, 't2_MAPE':t2_MAPE, 'rf_MAPE': rf_MAPE, 't1_MAE':t1_MAE, 't2_MAE':t2_MAE, 'rf_MAE':rf_MAE, 't1_accuracy':t1_accuracy, 't2_accuracy':t2_accuracy, 'rf_accuracy':rf_accuracy, 't1_RMSE':t1_RMSE, 't2_RMSE':t2_RMSE, 'rf_RMSE':rf_RMSE})\n",
        "\n",
        "y_predicted = model.predict([X1_test, X2_test], verbose=1) \n",
        "plot_true_v_predicted(y_test, y_predicted)\n",
        "show_prediction_metrics(y_test, y_predicted, parameters = 3)\n",
        "\n",
        "y_predicted = make_brain_predictions(brain_noise(phantom_re), brain_noise(phantom_im), model, 3)\n",
        "y_predicted = mask_brain(y_predicted)\n",
        "show_brain(y_predicted, np.array([phantom_t1, phantom_t2, phantom_rf]))\n",
        "print(brain_accuracy(np.array([phantom_t1, phantom_t2, phantom_rf]).transpose(1, 2, 0), y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}